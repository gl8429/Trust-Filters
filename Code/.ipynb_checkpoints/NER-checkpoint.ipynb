{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk,os\n",
    "import nltk.tag.stanford as st\n",
    "os.environ[\"CLASSPATH\"] = \"/Users/Lucifer/Documents/GraduateStudy/NLP/Trust-Filters/Code/stanford-ner-2014-06-16/stanford-ner.jar\"\n",
    "os.environ[\"STANFORD_MODELS\"] = \"/Users/Lucifer/Documents/GraduateStudy/NLP/Trust-Filters/Code/stanford-ner-2014-06-16/classifiers/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st1 = st.StanfordNERTagger('english.all.3class.distsim.crf.ser.gz')\n",
    "st2 = st.StanfordNERTagger('english.conll.4class.distsim.crf.ser.gz')\n",
    "st3 = st.StanfordNERTagger('english.muc.7class.distsim.crf.ser.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retrieve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9d838a3650f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LOC:state Which two states enclose Chesapeake Bay ?'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstrings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'retrieve' is not defined"
     ]
    }
   ],
   "source": [
    "sentence = 'LOC:state Which two states enclose Chesapeake Bay ?'\n",
    "strings = st3.tag(sentence.split()) \n",
    "sentences = [retrieve(strings)]\n",
    "sentences = [retrieve(strings)] + sentence.split()\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('LOC:state', 'O'), ('Which', 'O'), ('two', 'O'), ('states', 'O'), ('enclose', 'O'), ('Chesapeake', 'LOCATION'), ('Bay', 'LOCATION'), ('?', 'O')]\n",
      "Chesapeake_Bay\n"
     ]
    }
   ],
   "source": [
    "def retrieve(strings):\n",
    "    res = \"\"\n",
    "    for string in strings:\n",
    "        if string[1] != 'O':\n",
    "            res += string[0] + \"_\"\n",
    "    return res[:len(res) - 1]\n",
    "print(strings)\n",
    "print(retrieve(strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['DESC:manner', 'Russia', 'How', 'did', 'serfdom', 'develop', 'in', 'and', 'then', 'leave', 'Russia', '?'], ['ENTY:cremat', 'Popeye_Doyle', 'What', 'films', 'featured', 'the', 'character', 'Popeye', 'Doyle', '?'], ['DESC:manner', '', 'How', 'can', 'I', 'find', 'a', 'list', 'of', 'celebrities', \"'\", 'real', 'names', '?'], ['ENTY:animal', '', 'What', 'fowl', 'grabs', 'the', 'spotlight', 'after', 'the', 'Chinese', 'Year', 'of', 'the', 'Monkey', '?'], ['ABBR:exp', '', 'What', 'is', 'the', 'full', 'form', 'of', '.com', '?'], ['HUM:ind', '', 'What', 'contemptible', 'scoundrel', 'stole', 'the', 'cork', 'from', 'my', 'lunch', '?'], ['HUM:gr', 'St._Louis_Browns', 'What', 'team', 'did', 'baseball', \"'s\", 'St.', 'Louis', 'Browns', 'become', '?'], ['HUM:title', '', 'What', 'is', 'the', 'oldest', 'profession', '?'], ['DESC:def', '', 'What', 'are', 'liver', 'enzymes', '?'], ['HUM:ind', '', 'Name', 'the', 'scar-faced', 'bounty', 'hunter', 'of', 'The', 'Old', 'West', '.'], ['NUM:date', 'Ozzy_Osbourne', 'When', 'was', 'Ozzy', 'Osbourne', 'born', '?'], ['DESC:reason', '', 'Why', 'do', 'heavier', 'objects', 'travel', 'downhill', 'faster', '?'], ['HUM:ind', '', 'Who', 'was', 'The', 'Pride', 'of', 'the', 'Yankees', '?'], ['HUM:ind', 'Gandhi', 'Who', 'killed', 'Gandhi', '?'], ['ENTY:event', '', 'What', 'is', 'considered', 'the', 'costliest', 'disaster', 'the', 'insurance', 'industry', 'has', 'ever', 'faced', '?'], ['LOC:state', 'U.S.', 'What', 'sprawling', 'U.S.', 'state', 'boasts', 'the', 'most', 'airports', '?'], ['DESC:desc', 'U.S.', 'What', 'did', 'the', 'only', 'repealed', 'amendment', 'to', 'the', 'U.S.', 'Constitution', 'deal', 'with', '?'], ['NUM:count', '', 'How', 'many', 'Jews', 'were', 'executed', 'in', 'concentration', 'camps', 'during', 'WWII', '?'], ['DESC:def', '', 'What', 'is', '``', 'Nine', 'Inch', 'Nails', \"''\", '?'], ['DESC:def', '', 'What', 'is', 'an', 'annotated', 'bibliography', '?'], ['NUM:date', '', 'What', 'is', 'the', 'date', 'of', 'Boxing', 'Day', '?'], ['ENTY:other', '', 'What', 'articles', 'of', 'clothing', 'are', 'tokens', 'in', 'Monopoly', '?'], ['HUM:ind', '', 'Name', '11', 'famous', 'martyrs', '.'], ['DESC:desc', '', 'What', \"'s\", 'the', 'Olympic', 'motto', '?'], ['DESC:desc', 'Scarlett', 'What', 'is', 'the', 'origin', 'of', 'the', 'name', '`', 'Scarlett', \"'\", '?'], ['ENTY:letter', '', 'What', \"'s\", 'the', 'second-most-used', 'vowel', 'in', 'English', '?'], ['HUM:ind', '', 'Who', 'was', 'the', 'inventor', 'of', 'silly', 'putty', '?'], ['LOC:other', 'United_States', 'What', 'is', 'the', 'highest', 'waterfall', 'in', 'the', 'United', 'States', '?'], ['ENTY:other', 'Myrtle_Beach', 'Name', 'a', 'golf', 'course', 'in', 'Myrtle', 'Beach', '.'], ['LOC:state', 'Chesapeake_Bay', 'Which', 'two', 'states', 'enclose', 'Chesapeake', 'Bay', '?'], ['ABBR:exp', '', 'What', 'does', 'the', 'abbreviation', 'AIDS', 'stand', 'for', '?'], ['ENTY:other', '', 'What', 'does', 'a', 'spermologer', 'collect', '?']]\n"
     ]
    }
   ],
   "source": [
    "fileName = \"train1.txt\"\n",
    "with open(fileName, 'r') as fileInput:\n",
    "    sentences = []\n",
    "    for sentence in fileInput:\n",
    "        words = sentence.split()\n",
    "        strings = st3.tag(words)\n",
    "        sentence = [words[0]] + [retrieve(strings)] + words[1:]\n",
    "        sentences.append(sentence)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['DESC:manner', 'Russia', 'How', 'did', 'serfdom', 'develop', 'in', 'and', 'then', 'leave', 'Russia', '?'], ['ENTY:cremat', 'Popeye_Doyle', 'What', 'films', 'featured', 'the', 'character', 'Popeye', 'Doyle', '?'], ['DESC:manner', '', 'How', 'can', 'I', 'find', 'a', 'list', 'of', 'celebrities', \"'\", 'real', 'names', '?'], ['ENTY:animal', '', 'What', 'fowl', 'grabs', 'the', 'spotlight', 'after', 'the', 'Chinese', 'Year', 'of', 'the', 'Monkey', '?'], ['ABBR:exp', '', 'What', 'is', 'the', 'full', 'form', 'of', '.com', '?'], ['HUM:ind', '', 'What', 'contemptible', 'scoundrel', 'stole', 'the', 'cork', 'from', 'my', 'lunch', '?'], ['HUM:gr', 'St._Louis_Browns', 'What', 'team', 'did', 'baseball', \"'s\", 'St.', 'Louis', 'Browns', 'become', '?'], ['HUM:title', '', 'What', 'is', 'the', 'oldest', 'profession', '?'], ['DESC:def', '', 'What', 'are', 'liver', 'enzymes', '?'], ['HUM:ind', '', 'Name', 'the', 'scar-faced', 'bounty', 'hunter', 'of', 'The', 'Old', 'West', '.'], ['NUM:date', 'Ozzy_Osbourne', 'When', 'was', 'Ozzy', 'Osbourne', 'born', '?'], ['DESC:reason', '', 'Why', 'do', 'heavier', 'objects', 'travel', 'downhill', 'faster', '?'], ['HUM:ind', '', 'Who', 'was', 'The', 'Pride', 'of', 'the', 'Yankees', '?'], ['HUM:ind', 'Gandhi', 'Who', 'killed', 'Gandhi', '?'], ['ENTY:event', '', 'What', 'is', 'considered', 'the', 'costliest', 'disaster', 'the', 'insurance', 'industry', 'has', 'ever', 'faced', '?'], ['LOC:state', 'U.S.', 'What', 'sprawling', 'U.S.', 'state', 'boasts', 'the', 'most', 'airports', '?'], ['DESC:desc', 'U.S.', 'What', 'did', 'the', 'only', 'repealed', 'amendment', 'to', 'the', 'U.S.', 'Constitution', 'deal', 'with', '?'], ['NUM:count', '', 'How', 'many', 'Jews', 'were', 'executed', 'in', 'concentration', 'camps', 'during', 'WWII', '?'], ['DESC:def', '', 'What', 'is', '``', 'Nine', 'Inch', 'Nails', \"''\", '?'], ['DESC:def', '', 'What', 'is', 'an', 'annotated', 'bibliography', '?'], ['NUM:date', '', 'What', 'is', 'the', 'date', 'of', 'Boxing', 'Day', '?'], ['ENTY:other', '', 'What', 'articles', 'of', 'clothing', 'are', 'tokens', 'in', 'Monopoly', '?'], ['HUM:ind', '', 'Name', '11', 'famous', 'martyrs', '.'], ['DESC:desc', '', 'What', \"'s\", 'the', 'Olympic', 'motto', '?'], ['DESC:desc', 'Scarlett', 'What', 'is', 'the', 'origin', 'of', 'the', 'name', '`', 'Scarlett', \"'\", '?'], ['ENTY:letter', '', 'What', \"'s\", 'the', 'second-most-used', 'vowel', 'in', 'English', '?'], ['HUM:ind', '', 'Who', 'was', 'the', 'inventor', 'of', 'silly', 'putty', '?'], ['LOC:other', 'United_States', 'What', 'is', 'the', 'highest', 'waterfall', 'in', 'the', 'United', 'States', '?'], ['ENTY:other', 'Myrtle_Beach', 'Name', 'a', 'golf', 'course', 'in', 'Myrtle', 'Beach', '.'], ['LOC:state', 'Chesapeake_Bay', 'Which', 'two', 'states', 'enclose', 'Chesapeake', 'Bay', '?'], ['ABBR:exp', '', 'What', 'does', 'the', 'abbreviation', 'AIDS', 'stand', 'for', '?'], ['ENTY:other', '', 'What', 'does', 'a', 'spermologer', 'collect', '?']]\n"
     ]
    }
   ],
   "source": [
    "import gensim, logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "model = gensim.models.Word2Vec(sentences, size=100, window=5, min_count=1, workers=4)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "fileOutput = open('test.txt', 'w')\n",
    "for sentence in sentences:\n",
    "    for word in sentence:\n",
    "        stringArray = []\n",
    "        for num in model[word]:\n",
    "            stringArray.append(str(num))\n",
    "        fileOutput.write(\" \".join(stringArray))\n",
    "    fileOutput.write(\"\\n\\nNew Line\\n\\n\")\n",
    "fileOutput.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " sentences = [['first', 'sentence'], ['second', 'sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-0.0468569'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(model['The'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  3.93424183e-03,   4.11027391e-03,  -3.04277288e-03,\n",
       "         1.18999730e-03,   3.08968197e-03,   2.23310315e-03,\n",
       "         3.45678790e-03,   2.02281121e-03,  -2.53603398e-03,\n",
       "         2.35490035e-03,   2.97368038e-03,  -1.60179648e-03,\n",
       "         2.97981780e-03,  -3.33917397e-03,  -1.83241919e-03,\n",
       "        -1.73030235e-03,   1.02379685e-03,  -8.24019371e-04,\n",
       "        -1.66801526e-03,   2.18886510e-03,  -1.52525934e-03,\n",
       "         4.41671163e-03,   4.87298676e-04,  -1.14073313e-03,\n",
       "         1.71728758e-03,  -1.91683543e-03,   2.58652144e-03,\n",
       "         2.50605680e-03,  -2.75245262e-03,   1.82662287e-03,\n",
       "         2.98107439e-03,   2.38076737e-03,  -3.73732252e-03,\n",
       "        -1.04971894e-03,   6.42871775e-04,  -4.22969460e-03,\n",
       "        -4.11032327e-03,   4.46819002e-04,   4.69295448e-03,\n",
       "         4.30819346e-03,  -3.74551513e-03,   1.11623331e-05,\n",
       "        -1.68894604e-03,   3.23154358e-03,   2.67032813e-03,\n",
       "         1.70783955e-04,  -4.86536324e-03,  -2.64716009e-03,\n",
       "        -1.05553489e-04,   1.79979915e-03,   1.39185262e-03,\n",
       "         1.40913366e-03,   4.76178993e-03,   4.03800979e-03,\n",
       "         4.91179340e-03,  -2.08160933e-03,   2.61161570e-03,\n",
       "        -4.15234594e-03,  -3.74167785e-03,   2.41280999e-03,\n",
       "         1.81578659e-03,   1.69173197e-03,   1.78482221e-03,\n",
       "        -4.43248916e-03,   1.54527440e-03,  -1.94939377e-03,\n",
       "         3.75012681e-03,  -4.21400229e-03,  -1.54047937e-03,\n",
       "         2.88417912e-03,   3.61035531e-03,   3.40639235e-04,\n",
       "         4.77823988e-03,  -4.16271575e-03,   2.54329015e-03,\n",
       "         2.51817779e-04,   2.02778421e-04,  -3.96220479e-03,\n",
       "        -7.93370826e-04,  -3.79196688e-04,   4.17234143e-03,\n",
       "         2.68363673e-03,  -3.93844349e-03,  -5.14483079e-03,\n",
       "        -3.77808022e-03,  -2.16098805e-03,   1.97783462e-03,\n",
       "        -8.40500230e-04,   1.68819667e-03,   2.50080542e-04,\n",
       "         5.04702656e-03,   9.50833142e-04,   4.71195159e-03,\n",
       "         2.90529197e-03,   4.62797750e-03,  -1.56824407e-03,\n",
       "        -4.10800148e-03,   2.85310089e-04,   2.64930842e-03,\n",
       "        -4.83113294e-03], dtype=float32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(model['Russia']))\n",
    "print(len(model['The']))\n",
    "model['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
